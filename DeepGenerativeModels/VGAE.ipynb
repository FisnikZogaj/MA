{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T15:46:36.273442100Z",
     "start_time": "2024-05-29T15:46:36.241758Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    " \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.optim import Adam\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ZINC\n",
    "from torch_geometric.nn import VGAE, GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Challenges of Graph Generation: \n",
    "\n",
    "- A Graph with n nodes can be represented by up to n! equivalent adjacency matrices, each corresponding to a different, arbitrary node ordering. Given that a graph can have multiple representations, it is difficult for the models to calculate\n",
    "the distance between the generated graphs and groundtruth graphs white training. \n",
    "Thus it may require us to design\n",
    "either a **pre-defined node ordering** or a **node permutation\n",
    "invariant reconstruction objective function**.\n",
    "\n",
    "- Two nodes are more likely to be connected if they\n",
    "share common neighbors. Therefore, the generation of each\n",
    "node or edge **cannot** be modeled as an independent event\n",
    "\n",
    "- Large Output space due to n² adjacency matrix \n",
    "\n",
    "- Reconstructing the desecrate graph objects (i.e., nodes and\n",
    "edges) from continuous spaces results into different graph\n",
    "decoder process, such as sequentially generating the nodes\n",
    "of the graphs or generating the adjacent matrix of graphs in\n",
    "one-shot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28921b09e056563e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Positive Samples (pos_edge_index): These are the actual edges from the graph. The positive loss is calculated based on how well the model predicts the existence of these actual edges, encouraging the model to predict a high probability for the presence of edges that do exist.\n",
    "\n",
    "- Negative Samples (neg_edge_index): These are pairs of nodes that do not have an edge between them. The negative loss is computed based on how well the model predicts the absence of these non-existent edges, encouraging the model to predict a low probability for the presence of edges that do not exist.\n",
    "\n",
    "The combined loss function uses both of these components:\n",
    "\n",
    "- Positive Loss: Aims to minimize the negative log-likelihood of true edges (encouraging the model to assign high probabilities to real connections).\n",
    "- Negative Loss: Aims to minimize the negative log-likelihood of false edges (encouraging the model to assign low probabilities to non-existent connections)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e572a75f852ecd0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Standard Decoder Architecture: \n",
    "compute $\\tilde{A}_{i,j}$ based on the inner-product operations of two node embedding $Z_i$\n",
    "and $Z_j$ . This reflects the idea that nodes that are close in\n",
    "the embedding space should have a high probability of\n",
    "being connected"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18ec92972fc54392"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use nodes as batches, not graphs\n",
    "### much more flexible "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "178361bc350f045"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      split_labels=True, add_negative_train_samples=True)\n",
    "]) # Pipeline of transformations\n",
    "\n",
    "dataset = ZINC(root='/tmp/ZINC', subset=True, transform=transform)\n",
    "train_data_list, val_data_list, test_data_list = [], [], []\n",
    "for train_data, val_data, test_data in dataset:\n",
    "    try:\n",
    "        if val_data.neg_edge_label is not None:\n",
    "            train_data.x = F.normalize(train_data.x.float())\n",
    "            val_data.x = F.normalize(val_data.x.float())\n",
    "            test_data.x = F.normalize(test_data.x.float())\n",
    "            train_data_list.append(train_data)\n",
    "            val_data_list.append(val_data)\n",
    "            test_data_list.append(test_data)\n",
    "    except:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T15:43:02.837517100Z",
     "start_time": "2024-05-29T15:42:41.311617100Z"
    }
   },
   "id": "446e701e00ec1cfb"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data_list, batch_size=100, shuffle=True)\n",
    "val_loader = DataLoader(val_data_list, batch_size=4, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T15:44:48.466943600Z",
     "start_time": "2024-05-29T15:44:48.435700900Z"
    }
   },
   "id": "a2f2f33b20dfe3b2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        '''\n",
    "        :param input_dim: number of node_features\n",
    "        :param hidden_dim: For Convolution: latent representation of node features \n",
    "        :param latent_dim: Dimension of latent embedding z \n",
    "        '''\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim) # first layer \n",
    "        # Layers for GCN_mu and GCN_sigma\n",
    "        self.conv_mu = GCNConv(hidden_dim, latent_dim)\n",
    "        self.conv_logvar = GCNConv(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        # The reason for logvar, is because it yields negative and positive values \n",
    "        logvar = self.conv_logvar(x, edge_index)\n",
    "        return mu, logvar"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T15:43:48.003489Z",
     "start_time": "2024-05-29T15:43:47.972036100Z"
    }
   },
   "id": "f5038355584b4bf8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The encoder (inference model) of VGAE consists of graph convolutional networks (GCNs). It takes an adjacency\n",
    "matrix A and a feature matrix X as inputs and generates the latent variable Z as output. The first GCN layer\n",
    "generates a lower-dimensional feature matrix. It is defined as <br>\n",
    "\n",
    "$$\\( \\bar{X} \\) = GCN(X, A) = ReLU(\\( \\tilde{A} \\)XW_0)$$\n",
    "\n",
    "$ A \\in R^{nxn}$ and $X \\in R^{nxf}$, where X is $H^{(0)}$ and $W \\in R^{F^{(l)}xF^{(l+1)}}$\n",
    "\n",
    "A-tilde is the symmetrically normalized adjacency matrix.\n",
    "\n",
    "$$\\tilde{A} = \\( D^{-1/2} \\)A\\( D^{-1/2} \\) $$\n",
    "\n",
    "The second GCN layer generates μ and logσ², where\n",
    "$$\\mu = GCN_{\\mu}(X,A) = \\( \\tilde{A} \\)\\( \\bar{X} \\)W_{1}  $$\n",
    "$$log\\sigma² = GCN_{\\sigma}(X,A) = \\( \\tilde{A} \\)\\( \\bar{X} \\)W_{1}  $$\n",
    "Both $\\mu$ and log$\\sigma$ share the same computation \n",
    "\n",
    "Now if we combine the math of two-layer GCN together, we get\n",
    "...\n",
    "which generates μ and logσ².\n",
    "\n",
    "Then we can calculate Z using parameterization trick\n",
    "\n",
    "$$ Z = \\mu + \\sigma * \\epsilon $$\n",
    "\n",
    "where ε ~ N(0,1)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ce719fd599c6b2f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class GCNDecoder(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        ''' Better to only use inner Product layers (MLP)?'''\n",
    "        super(GCNDecoder, self).__init__()\n",
    "        self.conv1 = GCNConv(latent_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        x = F.relu(self.conv1(z, edge_index))\n",
    "        x = torch.sigmoid(self.conv2(x, edge_index))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class VGAE(torch.nn.Module):\n",
    "#    def __init__(self, encoder, decoder):\n",
    "#        super(VGAE, self).__init__()\n",
    "#        self.encoder = encoder\n",
    "#        self.decoder = decoder\n",
    "\n",
    "#    def reparameterize(self, mu, logvar):\n",
    "#        if self.training:\n",
    "#            std = torch.exp(0.5 * logvar) # why *  0.5? \n",
    "#            eps = torch.randn_like(std)\n",
    "#            return mu + eps * std\n",
    "#        else:\n",
    "#            return mu\n",
    "\n",
    "#    def forward(self, x, edge_index):\n",
    "#        mu, logvar = self.encoder(x, edge_index)\n",
    "#        z = self.reparameterize(mu, logvar)\n",
    "#        recon_x = self.decoder(z, edge_index)\n",
    "#        return recon_x, mu, logvar\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T15:43:42.975223800Z",
     "start_time": "2024-05-29T15:43:42.959602300Z"
    }
   },
   "id": "aa119cb91f872e12"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def generate_synthetic_graph(num_nodes):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_nodes, latent_dim).to(device)\n",
    "        edge_index = torch.combinations(torch.arange(num_nodes), r=2).t().to(device)\n",
    "        recon_x = model.decoder(z, edge_index)\n",
    "        return recon_x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T14:26:18.352342200Z"
    }
   },
   "id": "8927bb5168283a2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The degree to which the Auto Encoder simply reproduces the graph, depends on how small the **difference between the number of hidden dimensions and the number of input dimensions** is."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f67f72ebbe68966a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Configurate: \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model parameters for a smaller dataset\n",
    "input_dim = dataset.num_node_features\n",
    "hidden_dim = 16  # Adjusted hidden dimension\n",
    "latent_dim = 8   # Adjusted latent dimension\n",
    "\n",
    "# Initialize models with adjusted dimensions\n",
    "encoder = GCNEncoder(input_dim, hidden_dim, latent_dim).to(device)\n",
    "decoder = GCNDecoder(latent_dim, hidden_dim, input_dim).to(device)\n",
    "model = VGAE(encoder, decoder).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    \"\"\"\n",
    "    :return: Avg Train Loss for one epoch\n",
    "    called in the train Loop\n",
    "    One entire graph is processed at a time \n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    i = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # model is an instance of the VGAE class.\n",
    "        # The layers and forward method where passed as inputs to VGAE().\n",
    "        # def reparametrize(self, mu: Tensor, logstd: Tensor) -> Tensor:\n",
    "        # if self.training:\n",
    "        #    return mu + torch.randn_like(logstd) * torch.exp(logstd)\n",
    "        # else:\n",
    "        #    return mu\n",
    "        z = model.encode(data.x, data.edge_index) # only one tensor due to re-parametrize  \n",
    "        \n",
    "        # reconstruction loss: use both postive and negative samples (nodes with and without edges)\n",
    "        # since we want to predict both outcomes: edge or no edge\n",
    "        loss = model.recon_loss(z, data.pos_edge_label_index, data.neg_edge_label_index)\n",
    "        loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "        loss.backward()\n",
    "        loss_all += data.y.size(0) * float(loss) # (variable) batch size * loss\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_loss = loss_all / len(train_loader.dataset)\n",
    "    print(avg_loss)\n",
    "    \n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def val(loader):\n",
    "    model.eval()\n",
    "    auc_all, ap_all = 0, 0\n",
    "\n",
    "    for data in loader:\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        auc, ap = model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)\n",
    "        auc_all += data.y.size(0) * float(auc)\n",
    "        ap_all += data.y.size(0) * float(ap)\n",
    "    return auc_all / len(val_loader.dataset), ap_all / len(val_loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    \"\"\"\n",
    "    :param loader: test loader\n",
    "    :return: List of reconstructed Adj. Matrices.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    graph_adj = []\n",
    "    for graph, data in enumerate(loader):\n",
    "        # Model handles Graph size dynamically: why? \n",
    "        # Model encode implicitly calls the forward method and returns its output.\n",
    "        # here: return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        print(\"size of z: \", z.shape) # out_channels x num_nodes\n",
    "        recon_mat = model.decoder.forward_all(z)\n",
    "        print(\"size of A~: \", recon_mat.shape) # num_nodes x num_nodes \n",
    "        graph_adj.append(recon_mat) # append the reconstructed Adj. Matrix\n",
    "        if graph == gen_graphs - 1: # Condition if enough graphs are generated.\n",
    "            break\n",
    "    return graph_adj\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T15:46:59.923981400Z",
     "start_time": "2024-05-29T15:46:59.887197Z"
    }
   },
   "id": "581e21b5811645c9"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GCNDecoder.forward() got an unexpected keyword argument 'sigmoid'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m5\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;66;03m# auc, ap = val(val_loader)\u001B[39;00m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[13], line 39\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     35\u001B[0m z \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencode(data\u001B[38;5;241m.\u001B[39mx, data\u001B[38;5;241m.\u001B[39medge_index) \u001B[38;5;66;03m# only one tensor due to re-parametrize  \u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# reconstruction loss: use both postive and negative samples (nodes with and without edges)\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# since we want to predict both outcomes: edge or no edge\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecon_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpos_edge_label_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mneg_edge_label_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m data\u001B[38;5;241m.\u001B[39mnum_nodes) \u001B[38;5;241m*\u001B[39m model\u001B[38;5;241m.\u001B[39mkl_loss()\n\u001B[0;32m     41\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\PycharmProjects\\MA\\venv\\lib\\site-packages\\torch_geometric\\nn\\models\\autoencoder.py:106\u001B[0m, in \u001B[0;36mGAE.recon_loss\u001B[1;34m(self, z, pos_edge_index, neg_edge_index)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrecon_loss\u001B[39m(\u001B[38;5;28mself\u001B[39m, z: Tensor, pos_edge_index: Tensor,\n\u001B[0;32m     93\u001B[0m                neg_edge_index: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m     94\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Given latent variables :obj:`z`, computes the binary cross\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;124;03m    entropy loss for positive edges :obj:`pos_edge_index` and negative\u001B[39;00m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;124;03m    sampled edges.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;124;03m            calculate negative edges. (default: :obj:`None`)\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m    105\u001B[0m     pos_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlog(\n\u001B[1;32m--> 106\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_edge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigmoid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m EPS)\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m neg_edge_index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    109\u001B[0m         neg_edge_index \u001B[38;5;241m=\u001B[39m negative_sampling(pos_edge_index, z\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[1;32m~\\PycharmProjects\\MA\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MA\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: GCNDecoder.forward() got an unexpected keyword argument 'sigmoid'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5 + 1):\n",
    "    loss = train()\n",
    "    # auc, ap = val(val_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T15:47:04.412765900Z",
     "start_time": "2024-05-29T15:47:04.191710600Z"
    }
   },
   "id": "915846c566b66df9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff81b598348c2998"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ZINC\n",
    "from torch_geometric.nn import VGAE, GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T14:22:47.948514900Z",
     "start_time": "2024-05-27T14:22:47.935196400Z"
    }
   },
   "id": "d9a0eab800db2276"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      split_labels=True, add_negative_train_samples=True)\n",
    "])\n",
    "\n",
    "#Combines a single transformation step using T.Compose.\n",
    "#The T.RandomLinkSplit transformation:\n",
    "#Splits the graph's edges into training (85%), validation (5%), and test (10%) sets.\n",
    "#Treats the graph as undirected.\n",
    "#Generates labels for the split edges to indicate whether they are positive or negative samples.\n",
    "#Adds negative samples to the training set to facilitate link prediction tasks.\n",
    "\n",
    "dataset = ZINC(root='/tmp/ZINC', subset=True, transform=transform)\n",
    "train_data_list, val_data_list, test_data_list = [], [], []\n",
    "for train_data, val_data, test_data in dataset:\n",
    "    try:\n",
    "        if val_data.neg_edge_label is not None:\n",
    "            train_data.x = F.normalize(train_data.x.float())\n",
    "            val_data.x = F.normalize(val_data.x.float())\n",
    "            test_data.x = F.normalize(test_data.x.float())\n",
    "            train_data_list.append(train_data)\n",
    "            val_data_list.append(val_data)\n",
    "            test_data_list.append(test_data)\n",
    "    except:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T14:23:34.629142900Z",
     "start_time": "2024-05-27T14:22:50.605090600Z"
    }
   },
   "id": "1201a0e1a43d1452"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T14:22:04.401809Z",
     "start_time": "2024-05-27T14:22:04.382398300Z"
    }
   },
   "id": "63d26709f81f85cd"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "in_channels, out_channels, lr, n_epochs = dataset.num_features, 16, 1e-2, 5 # num_features = 1\n",
    "gen_graphs, threshold, batch_size, add_self_loops = 5, 0.5, 2, True\n",
    "model = VGAE(VariationalGCNEncoder(in_channels, out_channels))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_loader = DataLoader(train_data_list, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data_list, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T14:05:57.718409400Z",
     "start_time": "2024-05-27T14:05:57.710320Z"
    }
   },
   "id": "c88198ae2f6a2ff9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
