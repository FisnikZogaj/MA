{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T13:26:34.220708Z",
     "start_time": "2024-05-21T13:26:28.241038Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    " \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.optim import Adam\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=-UjytpbqX4A&t=15s -> 1:10:30"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aa43fc976e734b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Challenges of Graph Generation: \n",
    "\n",
    "- A Graph with n nodes can be represented by up to n! equivalent adjacency matrices, each corresponding to a different, arbitrary node ordering. Given that a graph can have multiple representations, it is difficult for the models to calculate\n",
    "the distance between the generated graphs and groundtruth graphs white training. \n",
    "Thus it may require us to design\n",
    "either a **pre-defined node ordering** or a **node permutation\n",
    "invariant reconstruction objective function**.\n",
    "\n",
    "- Two nodes are more likely to be connected if they\n",
    "share common neighbors. Therefore, the generation of each\n",
    "node or edge **cannot** be modeled as an independent event\n",
    "\n",
    "- Large Output space due to n² adjacency matrix \n",
    "\n",
    "- Reconstructing the desecrate graph objects (i.e., nodes and\n",
    "edges) from continuous spaces results into different graph\n",
    "decoder process, such as sequentially generating the nodes\n",
    "of the graphs or generating the adjacent matrix of graphs in\n",
    "one-shot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28921b09e056563e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.data.data.Data'>\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([2, 78])\n"
     ]
    }
   ],
   "source": [
    "def create_small_graph():\n",
    "    G = nx.karate_club_graph()  # Creating a small example graph\n",
    "    edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()\n",
    "    x = torch.eye(G.number_of_nodes(), dtype=torch.float)  # One-hot encoding of node features\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    return data\n",
    "\n",
    "data = create_small_graph()\n",
    "print(type(data))\n",
    "print(data.x)\n",
    "print(data.edge_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T13:27:40.343736100Z",
     "start_time": "2024-05-21T13:27:40.328115800Z"
    }
   },
   "id": "5d374a88b9ab30eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Standard Decoder Architecture: \n",
    "compute $\\tilde{A}_{i,j}$ based on the inner-product operations of two node embedding $Z_i$\n",
    "and $Z_j$ . This reflects the idea that nodes that are close in\n",
    "the embedding space should have a high probability of\n",
    "being connected"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18ec92972fc54392"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        '''\n",
    "        :param input_dim: number of node_features\n",
    "        :param hidden_dim: For Convolution: latent representation of node features \n",
    "        :param latent_dim: Dimension of latent embedding z \n",
    "        '''\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim) # first layer \n",
    "        # Layers for GCN_mu and GCN_sigma\n",
    "        self.conv_mu = GCNConv(hidden_dim, latent_dim)\n",
    "        self.conv_logvar = GCNConv(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        # The reason for logvar, is because it yields negative and positive values \n",
    "        logvar = self.conv_logvar(x, edge_index)\n",
    "        return mu, logvar\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T14:25:50.357093100Z",
     "start_time": "2024-05-21T14:25:50.216762100Z"
    }
   },
   "id": "f5038355584b4bf8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The encoder (inference model) of VGAE consists of graph convolutional networks (GCNs). It takes an adjacency\n",
    "matrix A and a feature matrix X as inputs and generates the latent variable Z as output. The first GCN layer\n",
    "generates a lower-dimensional feature matrix. It is defined as <br>\n",
    "\n",
    "$$\\( \\bar{X} \\) = GCN(X, A) = ReLU(\\( \\tilde{A} \\)XW_0)$$\n",
    "\n",
    "$ A \\in R^{nxn}$ and $X \\in R^{nxf}$, where X is $H^{(0)}$ and $W \\in R^{F^{(l)}xF^{(l+1)}}$\n",
    "\n",
    "A-tilde is the symmetrically normalized adjacency matrix.\n",
    "\n",
    "$$\\tilde{A} = \\( D^{-1/2} \\)A\\( D^{-1/2} \\) $$\n",
    "\n",
    "The second GCN layer generates μ and logσ², where\n",
    "$$\\mu = GCN_{\\mu}(X,A) = \\( \\tilde{A} \\)\\( \\bar{X} \\)W_{1}  $$\n",
    "$$log\\sigma² = GCN_{\\sigma}(X,A) = \\( \\tilde{A} \\)\\( \\bar{X} \\)W_{1}  $$\n",
    "Both $\\mu$ and log$\\sigma$ share the same computation \n",
    "\n",
    "Now if we combine the math of two-layer GCN together, we get\n",
    "...\n",
    "which generates μ and logσ².\n",
    "\n",
    "Then we can calculate Z using parameterization trick\n",
    "\n",
    "$$ Z = \\mu + \\sigma * \\epsilon $$\n",
    "\n",
    "where ε ~ N(0,1)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ce719fd599c6b2f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class GCNDecoder(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        ''' Better to only use inner Product layers (MLP)?'''\n",
    "        super(GCNDecoder, self).__init__()\n",
    "        self.conv1 = GCNConv(latent_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        x = F.relu(self.conv1(z, edge_index))\n",
    "        x = torch.sigmoid(self.conv2(x, edge_index))\n",
    "        return x\n",
    "\n",
    "class VGAE(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VGAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar) # why *  0.5? \n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        mu, logvar = self.encoder(x, edge_index)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decoder(z, edge_index)\n",
    "        return recon_x, mu, logvar\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T14:25:53.042062700Z",
     "start_time": "2024-05-21T14:25:53.026401500Z"
    }
   },
   "id": "aa119cb91f872e12"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def generate_synthetic_graph(num_nodes):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_nodes, latent_dim).to(device)\n",
    "        edge_index = torch.combinations(torch.arange(num_nodes), r=2).t().to(device)\n",
    "        recon_x = model.decoder(z, edge_index)\n",
    "        return recon_x\n",
    "\n",
    "# Generate a synthetic graph with the same number of nodes as the small graph\n",
    "synthetic_graph = generate_synthetic_graph(data.num_nodes)\n",
    "# Convert the output to an adjacency matrix\n",
    "synthetic_adj_matrix = (synthetic_graph > 0.5).float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T14:26:18.352342200Z"
    }
   },
   "id": "8927bb5168283a2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The degree to which the Auto Encoder simply reproduces the graph, depends on how small the **difference between the number of hidden dimensions and the number of input dimensions** is."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f67f72ebbe68966a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Configurate: \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model parameters for a smaller dataset\n",
    "input_dim = data.num_node_features\n",
    "hidden_dim = 16  # Adjusted hidden dimension\n",
    "latent_dim = 8   # Adjusted latent dimension\n",
    "\n",
    "# Initialize models with adjusted dimensions\n",
    "encoder = GCNEncoder(input_dim, hidden_dim, latent_dim).to(device)\n",
    "decoder = GCNDecoder(latent_dim, hidden_dim, input_dim).to(device)\n",
    "model = VGAE(encoder, decoder).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    recon_x, mu, logvar = model(data.x, data.edge_index)\n",
    "    loss = model.loss_function(recon_x, data.x, mu, logvar)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(recon_x, x, # For BCE\n",
    "                  mu, logvar): # FOR KLD \n",
    "    '''PyTorch dynamically builds and traverses the computational graph, applying the chain rule to compute gradients for all operations involved\n",
    "    Each tensor operation (torch.sum, logvar.pow(2), logvar.exp(), etc.) has a known gradient. PyTorch tracks these operations and builds a backward function that can compute the gradient for each of these operations.'''\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # should be legit \n",
    "    return BCE + KLD\n",
    "\n",
    "model.loss_function = loss_function\n",
    "\n",
    "# Load data\n",
    "data = data.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T14:26:08.024654400Z"
    }
   },
   "id": "581e21b5811645c9"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 782.3570\n",
      "Epoch 10, Loss: 482.3631\n",
      "Epoch 20, Loss: 254.7292\n",
      "Epoch 30, Loss: 235.6179\n",
      "Epoch 40, Loss: 201.7655\n",
      "Epoch 50, Loss: 194.7714\n",
      "Epoch 60, Loss: 183.9261\n",
      "Epoch 70, Loss: 172.0984\n",
      "Epoch 80, Loss: 171.5353\n",
      "Epoch 90, Loss: 167.1517\n",
      "Epoch 100, Loss: 174.7078\n",
      "Epoch 110, Loss: 179.3512\n",
      "Epoch 120, Loss: 160.6138\n",
      "Epoch 130, Loss: 167.1098\n",
      "Epoch 140, Loss: 161.7437\n",
      "Epoch 150, Loss: 163.6620\n",
      "Epoch 160, Loss: 162.6941\n",
      "Epoch 170, Loss: 156.4730\n",
      "Epoch 180, Loss: 156.8359\n",
      "Epoch 190, Loss: 161.4288\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    # What is an epoch? one node? \n",
    "    loss = train(data)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T14:26:11.591634500Z"
    }
   },
   "id": "9e3fa7f8ae91272e"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.2222, -0.3827, -0.8971, -0.2272,  0.1467,  0.3660,  0.8537, -0.9697],\n        [-0.1939, -1.0909, -0.8521,  0.4935,  0.3323, -0.3392, -2.7095, -0.3395],\n        [-0.3465,  0.7839, -1.3669,  0.9866, -1.5625, -0.0280,  1.8097,  0.2726],\n        [-0.1660,  0.8072,  1.0152,  0.0068,  1.6382, -0.1477, -0.5107,  0.8677],\n        [ 0.2184, -0.5799,  0.5228,  0.5028, -1.0484, -0.9361, -1.8016, -0.6611],\n        [-0.1086, -0.8943, -0.4106, -0.0602, -0.2080, -0.3285, -1.1321,  1.7652],\n        [-1.1012,  0.5215,  0.5605,  1.5581,  0.2170, -1.3616, -0.7893,  0.4434],\n        [-0.9681,  0.4497, -0.4210,  0.1436, -0.1801,  0.7429, -1.4777,  0.7788],\n        [-0.2805,  0.6716, -0.6382,  1.0572,  0.3380,  1.0947,  0.8290, -0.7078],\n        [-0.5782, -1.3198,  0.0367, -0.1153, -0.2776,  0.5019, -0.2993, -0.6841],\n        [ 1.6371,  0.0761,  1.3484,  0.2744, -0.5625,  0.0747, -1.0176, -0.5474],\n        [ 0.0748, -0.3228,  0.1408,  1.1832, -1.2772,  0.0453,  0.9017, -0.2338],\n        [ 0.1047, -0.7056,  0.1718,  0.2579,  0.9042, -0.9479,  1.2480, -1.1959],\n        [ 1.1087,  1.8014,  1.0693, -0.6093, -0.9304,  2.1821, -0.1887,  2.2264],\n        [-1.3955, -0.8602, -0.3501,  0.9758,  2.0883,  0.3048, -2.2800, -0.7414],\n        [-0.6327,  1.2593,  0.0900,  0.8053,  1.1008, -0.1204, -0.2023, -0.7676],\n        [ 0.2058, -1.2831,  0.9113,  0.3278, -0.6620,  0.8654,  0.5635, -0.6744],\n        [ 1.3324,  1.2802, -1.2146,  1.8083, -0.4710, -0.6727,  0.5399, -0.5125],\n        [ 0.7873, -0.5778,  1.7015,  0.2288,  1.7991,  1.5052,  1.1883, -0.2057],\n        [ 0.1483, -0.1778,  0.4914,  1.0759, -0.5298,  1.1884,  1.0034,  0.3398],\n        [-1.9898,  0.6423, -0.5356, -1.2986, -1.0291, -0.2407, -0.3547, -1.5674],\n        [-0.3383,  0.0738,  0.6349,  0.1008, -0.4875, -0.3101, -0.7042,  1.0724],\n        [-0.1391, -1.3072, -0.0345,  0.5004, -0.8445, -1.0832, -0.4233, -0.1654],\n        [-0.9235, -0.0563,  0.4876,  0.1139, -1.2984, -1.3273, -0.5058,  0.7289],\n        [-1.2561,  1.5601, -0.2184,  0.4799, -0.1352,  0.3038, -0.9727, -0.5679],\n        [ 0.7196,  0.4730,  1.6019,  0.8683,  1.4946, -0.8508,  0.1333, -0.0975],\n        [ 1.6487,  0.0468, -0.0692, -0.5266, -1.5421, -0.0320,  0.0480, -1.0320],\n        [-0.6735, -0.0637,  0.0587, -0.7247, -0.9589, -0.7859, -0.6396, -0.7215],\n        [-1.0286,  0.3107,  1.3354, -2.5396,  0.1293, -0.5457,  1.2349, -1.3401],\n        [-2.2881, -0.3810, -0.5052, -0.2845, -1.4754, -0.8011, -0.0416,  0.7964],\n        [-0.4218, -0.1171,  0.7566,  0.5547, -0.2360, -0.8762,  0.8885, -0.7130],\n        [ 0.4666,  1.7663, -0.2995,  0.2289,  0.4276,  0.3845,  3.0015,  0.2896],\n        [ 0.1802, -0.2803, -1.2986, -0.9753,  0.7528, -1.6261,  0.5164,  0.5084],\n        [ 1.3191, -1.1831, -0.2029,  1.5297, -0.3810,  1.4458, -0.3494,  0.1626]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(data.num_nodes, latent_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T14:26:41.063493Z"
    }
   },
   "id": "b4de5cb7f4e8d35e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### New Approach "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff81b598348c2998"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ZINC\n",
    "from torch_geometric.nn import VGAE, GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T14:22:47.948514900Z",
     "start_time": "2024-05-27T14:22:47.935196400Z"
    }
   },
   "id": "d9a0eab800db2276"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      split_labels=True, add_negative_train_samples=True)\n",
    "])\n",
    "\n",
    "#Combines a single transformation step using T.Compose.\n",
    "#The T.RandomLinkSplit transformation:\n",
    "#Splits the graph's edges into training (85%), validation (5%), and test (10%) sets.\n",
    "#Treats the graph as undirected.\n",
    "#Generates labels for the split edges to indicate whether they are positive or negative samples.\n",
    "#Adds negative samples to the training set to facilitate link prediction tasks.\n",
    "\n",
    "dataset = ZINC(root='/tmp/ZINC', subset=True, transform=transform)\n",
    "train_data_list, val_data_list, test_data_list = [], [], []\n",
    "for train_data, val_data, test_data in dataset:\n",
    "    try:\n",
    "        if val_data.neg_edge_label is not None:\n",
    "            train_data.x = F.normalize(train_data.x.float())\n",
    "            val_data.x = F.normalize(val_data.x.float())\n",
    "            test_data.x = F.normalize(test_data.x.float())\n",
    "            train_data_list.append(train_data)\n",
    "            val_data_list.append(val_data)\n",
    "            test_data_list.append(test_data)\n",
    "    except:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T14:23:34.629142900Z",
     "start_time": "2024-05-27T14:22:50.605090600Z"
    }
   },
   "id": "1201a0e1a43d1452"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T14:22:04.401809Z",
     "start_time": "2024-05-27T14:22:04.382398300Z"
    }
   },
   "id": "63d26709f81f85cd"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "in_channels, out_channels, lr, n_epochs = dataset.num_features, 16, 1e-2, 5 # num_features = 1\n",
    "gen_graphs, threshold, batch_size, add_self_loops = 5, 0.5, 2, True\n",
    "model = VGAE(VariationalGCNEncoder(in_channels, out_channels))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_loader = DataLoader(train_data_list, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data_list, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T14:05:57.718409400Z",
     "start_time": "2024-05-27T14:05:57.710320Z"
    }
   },
   "id": "c88198ae2f6a2ff9"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T14:22:09.616981400Z",
     "start_time": "2024-05-27T14:22:09.612758200Z"
    }
   },
   "id": "41b7a54d0d3987e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
