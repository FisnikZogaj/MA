{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[Github](https://github.com/dmlc/dgl/tree/master/examples/pytorch/dgmg)\n",
    "\n",
    "**Very specific to Cycle graphs**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "265a55ef0bb6b12a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from DeepGenerativeModels.DGMG.model import DGMG\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Bernoulli, Categorical\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c88884f35348b8fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utils"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18eafdcdabaa1d26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    Code from https://gist.github.com/jeasinema/ed9236ce743c8efaf30fa2ff732749f5\n",
    "    Usage:\n",
    "        model = Model()\n",
    "        model.apply(weight_init)\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.GRUCell):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "\n",
    "\n",
    "def dgmg_message_weight_init(m):\n",
    "    \"\"\"\n",
    "    This is similar as the function above where we initialize linear layers from a normal distribution with std\n",
    "    1./10 as suggested by the author. This should only be used for the message passing functions, i.e. fe's in the\n",
    "    paper.\n",
    "    \"\"\"\n",
    "\n",
    "    def _weight_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            init.normal_(m.weight.data, std=1.0 / 10)\n",
    "            init.normal_(m.bias.data, std=1.0 / 10)\n",
    "        else:\n",
    "            raise ValueError(\"Expected the input to be of type nn.Linear!\")\n",
    "\n",
    "    if isinstance(m, nn.ModuleList):\n",
    "        for layer in m:\n",
    "            layer.apply(_weight_init)\n",
    "    else:\n",
    "        m.apply(_weight_init)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2777f0ea75a67df5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4af6e16600b94e12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9ef2da58c4136e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GraphEmbed(nn.Module):\n",
    "    def __init__(self, node_hidden_size):\n",
    "        super(GraphEmbed, self).__init__()\n",
    "\n",
    "        # Setting from the paper\n",
    "        self.graph_hidden_size = 2 * node_hidden_size\n",
    "\n",
    "        # Embed graphs\n",
    "        self.node_gating = nn.Sequential(\n",
    "            nn.Linear(node_hidden_size, 1), nn.Sigmoid()\n",
    "        )\n",
    "        self.node_to_graph = nn.Linear(node_hidden_size, self.graph_hidden_size)\n",
    "\n",
    "    def forward(self, g):\n",
    "        if g.num_nodes() == 0:\n",
    "            return torch.zeros(1, self.graph_hidden_size)\n",
    "        else:\n",
    "            # Node features are stored as hv in ndata.\n",
    "            hvs = g.ndata[\"hv\"]\n",
    "            return (self.node_gating(hvs) * self.node_to_graph(hvs)).sum(\n",
    "                0, keepdim=True\n",
    "            )\n",
    "\n",
    "class GraphProp(nn.Module):\n",
    "    def __init__(self, num_prop_rounds, node_hidden_size):\n",
    "        super(GraphProp, self).__init__()\n",
    "\n",
    "        self.num_prop_rounds = num_prop_rounds\n",
    "\n",
    "        # Setting from the paper\n",
    "        self.node_activation_hidden_size = 2 * node_hidden_size\n",
    "\n",
    "        message_funcs = []\n",
    "        self.reduce_funcs = []\n",
    "        node_update_funcs = []\n",
    "\n",
    "        for t in range(num_prop_rounds):\n",
    "            # input being [hv, hu, xuv]\n",
    "            message_funcs.append(\n",
    "                nn.Linear(\n",
    "                    2 * node_hidden_size + 1, self.node_activation_hidden_size\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.reduce_funcs.append(partial(self.dgmg_reduce, round=t))\n",
    "            node_update_funcs.append(\n",
    "                nn.GRUCell(self.node_activation_hidden_size, node_hidden_size)\n",
    "            )\n",
    "\n",
    "        self.message_funcs = nn.ModuleList(message_funcs)\n",
    "        self.node_update_funcs = nn.ModuleList(node_update_funcs)\n",
    "\n",
    "    def dgmg_msg(self, edges):\n",
    "        \"\"\"For an edge u->v, return concat([h_u, x_uv])\"\"\"\n",
    "        return {\"m\": torch.cat([edges.src[\"hv\"], edges.data[\"he\"]], dim=1)}\n",
    "\n",
    "    def dgmg_reduce(self, nodes, round):\n",
    "        hv_old = nodes.data[\"hv\"]\n",
    "        m = nodes.mailbox[\"m\"]\n",
    "        message = torch.cat(\n",
    "            [hv_old.unsqueeze(1).expand(-1, m.size(1), -1), m], dim=2\n",
    "        )\n",
    "        node_activation = (self.message_funcs[round](message)).sum(1)\n",
    "\n",
    "        return {\"a\": node_activation}\n",
    "\n",
    "    def forward(self, g):\n",
    "        if g.num_edges() == 0:\n",
    "            return\n",
    "        else:\n",
    "            for t in range(self.num_prop_rounds):\n",
    "                g.update_all(\n",
    "                    message_func=self.dgmg_msg, reduce_func=self.reduce_funcs[t]\n",
    "                )\n",
    "                g.ndata[\"hv\"] = self.node_update_funcs[t](\n",
    "                    g.ndata[\"a\"], g.ndata[\"hv\"]\n",
    "                )\n",
    "\n",
    "def bernoulli_action_log_prob(logit, action):\n",
    "    \"\"\"Calculate the log p of an action with respect to a Bernoulli\n",
    "    distribution. Use logit rather than prob for numerical stability.\"\"\"\n",
    "    if action == 0:\n",
    "        return F.logsigmoid(-logit)\n",
    "    else:\n",
    "        return F.logsigmoid(logit)\n",
    "\n",
    "class AddNode(nn.Module):\n",
    "    def __init__(self, graph_embed_func, node_hidden_size):\n",
    "        super(AddNode, self).__init__()\n",
    "\n",
    "        self.graph_op = {\"embed\": graph_embed_func}\n",
    "\n",
    "        self.stop = 1\n",
    "        self.add_node = nn.Linear(graph_embed_func.graph_hidden_size, 1)\n",
    "\n",
    "        # If to add a node, initialize its hv\n",
    "        self.node_type_embed = nn.Embedding(1, node_hidden_size)\n",
    "        self.initialize_hv = nn.Linear(\n",
    "            node_hidden_size + graph_embed_func.graph_hidden_size,\n",
    "            node_hidden_size,\n",
    "        )\n",
    "\n",
    "        self.init_node_activation = torch.zeros(1, 2 * node_hidden_size)\n",
    "\n",
    "    def _initialize_node_repr(self, g, node_type, graph_embed):\n",
    "        num_nodes = g.num_nodes()\n",
    "        hv_init = self.initialize_hv(\n",
    "            torch.cat(\n",
    "                [\n",
    "                    self.node_type_embed(torch.LongTensor([node_type])),\n",
    "                    graph_embed,\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        )\n",
    "        g.nodes[num_nodes - 1].data[\"hv\"] = hv_init\n",
    "        g.nodes[num_nodes - 1].data[\"a\"] = self.init_node_activation\n",
    "\n",
    "    def prepare_training(self):\n",
    "        self.log_prob = []\n",
    "\n",
    "    def forward(self, g, action=None):\n",
    "        graph_embed = self.graph_op[\"embed\"](g)\n",
    "\n",
    "        logit = self.add_node(graph_embed)\n",
    "        prob = torch.sigmoid(logit)\n",
    "\n",
    "        if not self.training:\n",
    "            action = Bernoulli(prob).sample().item()\n",
    "        stop = bool(action == self.stop)\n",
    "\n",
    "        if not stop:\n",
    "            g.add_nodes(1)\n",
    "            self._initialize_node_repr(g, action, graph_embed)\n",
    "\n",
    "        if self.training:\n",
    "            sample_log_prob = bernoulli_action_log_prob(logit, action)\n",
    "            self.log_prob.append(sample_log_prob)\n",
    "\n",
    "        return stop\n",
    "\n",
    "class AddEdge(nn.Module):\n",
    "    def __init__(self, graph_embed_func, node_hidden_size):\n",
    "        super(AddEdge, self).__init__()\n",
    "\n",
    "        self.graph_op = {\"embed\": graph_embed_func}\n",
    "        self.add_edge = nn.Linear(\n",
    "            graph_embed_func.graph_hidden_size + node_hidden_size, 1\n",
    "        )\n",
    "\n",
    "    def prepare_training(self):\n",
    "        self.log_prob = []\n",
    "\n",
    "    def forward(self, g, action=None):\n",
    "        graph_embed = self.graph_op[\"embed\"](g)\n",
    "        src_embed = g.nodes[g.num_nodes() - 1].data[\"hv\"]\n",
    "\n",
    "        logit = self.add_edge(torch.cat([graph_embed, src_embed], dim=1))\n",
    "        prob = torch.sigmoid(logit)\n",
    "\n",
    "        if not self.training:\n",
    "            action = Bernoulli(prob).sample().item()\n",
    "        to_add_edge = bool(action == 0)\n",
    "\n",
    "        if self.training:\n",
    "            sample_log_prob = bernoulli_action_log_prob(logit, action)\n",
    "            self.log_prob.append(sample_log_prob)\n",
    "\n",
    "        return to_add_edge\n",
    "\n",
    "class ChooseDestAndUpdate(nn.Module):\n",
    "    def __init__(self, graph_prop_func, node_hidden_size):\n",
    "        super(ChooseDestAndUpdate, self).__init__()\n",
    "\n",
    "        self.graph_op = {\"prop\": graph_prop_func}\n",
    "        self.choose_dest = nn.Linear(2 * node_hidden_size, 1)\n",
    "\n",
    "    def _initialize_edge_repr(self, g, src_list, dest_list):\n",
    "        # For untyped edges, we only add 1 to indicate its existence.\n",
    "        # For multiple edge types, we can use a one hot representation\n",
    "        # or an embedding module.\n",
    "        edge_repr = torch.ones(len(src_list), 1)\n",
    "        g.edges[src_list, dest_list].data[\"he\"] = edge_repr\n",
    "\n",
    "    def prepare_training(self):\n",
    "        self.log_prob = []\n",
    "\n",
    "    def forward(self, g, dest):\n",
    "        src = g.num_nodes() - 1\n",
    "        possible_dests = range(src)\n",
    "\n",
    "        src_embed_expand = g.nodes[src].data[\"hv\"].expand(src, -1)\n",
    "        possible_dests_embed = g.nodes[possible_dests].data[\"hv\"]\n",
    "\n",
    "        dests_scores = self.choose_dest(\n",
    "            torch.cat([possible_dests_embed, src_embed_expand], dim=1)\n",
    "        ).view(1, -1)\n",
    "        dests_probs = F.softmax(dests_scores, dim=1)\n",
    "\n",
    "        if not self.training:\n",
    "            dest = Categorical(dests_probs).sample().item()\n",
    "\n",
    "        if not g.has_edges_between(src, dest):\n",
    "            # For undirected graphs, we add edges for both directions\n",
    "            # so that we can perform graph propagation.\n",
    "            src_list = [src, dest]\n",
    "            dest_list = [dest, src]\n",
    "\n",
    "            g.add_edges(src_list, dest_list)\n",
    "            self._initialize_edge_repr(g, src_list, dest_list)\n",
    "\n",
    "            self.graph_op[\"prop\"](g)\n",
    "\n",
    "        if self.training:\n",
    "            if dests_probs.nelement() > 1:\n",
    "                self.log_prob.append(\n",
    "                    F.log_softmax(dests_scores, dim=1)[:, dest : dest + 1]\n",
    "                )\n",
    "\n",
    "class DGMG(nn.Module):\n",
    "    def __init__(self, v_max, node_hidden_size, num_prop_rounds):\n",
    "        super(DGMG, self).__init__()\n",
    "\n",
    "        # Graph configuration\n",
    "        self.v_max = v_max\n",
    "\n",
    "        # Graph embedding module\n",
    "        self.graph_embed = GraphEmbed(node_hidden_size)\n",
    "\n",
    "        # Graph propagation module\n",
    "        self.graph_prop = GraphProp(num_prop_rounds, node_hidden_size)\n",
    "\n",
    "        # Actions\n",
    "        self.add_node_agent = AddNode(self.graph_embed, node_hidden_size)\n",
    "        self.add_edge_agent = AddEdge(self.graph_embed, node_hidden_size)\n",
    "        self.choose_dest_agent = ChooseDestAndUpdate(\n",
    "            self.graph_prop, node_hidden_size\n",
    "        )\n",
    "\n",
    "        # Weight initialization\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        from utils import dgmg_message_weight_init, weights_init\n",
    "\n",
    "        self.graph_embed.apply(weights_init)\n",
    "        self.graph_prop.apply(weights_init)\n",
    "        self.add_node_agent.apply(weights_init)\n",
    "        self.add_edge_agent.apply(weights_init)\n",
    "        self.choose_dest_agent.apply(weights_init)\n",
    "\n",
    "        self.graph_prop.message_funcs.apply(dgmg_message_weight_init)\n",
    "\n",
    "    @property\n",
    "    def action_step(self):\n",
    "        old_step_count = self.step_count\n",
    "        self.step_count += 1\n",
    "\n",
    "        return old_step_count\n",
    "\n",
    "    def prepare_for_train(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.add_node_agent.prepare_training()\n",
    "        self.add_edge_agent.prepare_training()\n",
    "        self.choose_dest_agent.prepare_training()\n",
    "\n",
    "    def add_node_and_update(self, a=None):\n",
    "        \"\"\"Decide if to add a new node.\n",
    "        If a new node should be added, update the graph.\"\"\"\n",
    "\n",
    "        return self.add_node_agent(self.g, a)\n",
    "\n",
    "    def add_edge_or_not(self, a=None):\n",
    "        \"\"\"Decide if a new edge should be added.\"\"\"\n",
    "\n",
    "        return self.add_edge_agent(self.g, a)\n",
    "\n",
    "    def choose_dest_and_update(self, a=None):\n",
    "        \"\"\"Choose destination and connect it to the latest node.\n",
    "        Add edges for both directions and update the graph.\"\"\"\n",
    "\n",
    "        self.choose_dest_agent(self.g, a)\n",
    "\n",
    "    def get_log_prob(self):\n",
    "        return (\n",
    "            torch.cat(self.add_node_agent.log_prob).sum()\n",
    "            + torch.cat(self.add_edge_agent.log_prob).sum()\n",
    "            + torch.cat(self.choose_dest_agent.log_prob).sum()\n",
    "        )\n",
    "\n",
    "    def forward_train(self, actions):\n",
    "        self.prepare_for_train()\n",
    "\n",
    "        stop = self.add_node_and_update(a=actions[self.action_step])\n",
    "\n",
    "        while not stop:\n",
    "            to_add_edge = self.add_edge_or_not(a=actions[self.action_step])\n",
    "            while to_add_edge:\n",
    "                self.choose_dest_and_update(a=actions[self.action_step])\n",
    "                to_add_edge = self.add_edge_or_not(a=actions[self.action_step])\n",
    "            stop = self.add_node_and_update(a=actions[self.action_step])\n",
    "\n",
    "        return self.get_log_prob()\n",
    "\n",
    "    def forward_inference(self):\n",
    "        stop = self.add_node_and_update()\n",
    "        while (not stop) and (self.g.num_nodes() < self.v_max + 1):\n",
    "            num_trials = 0\n",
    "            to_add_edge = self.add_edge_or_not()\n",
    "            while to_add_edge and (num_trials < self.g.num_nodes() - 1):\n",
    "                self.choose_dest_and_update()\n",
    "                num_trials += 1\n",
    "                to_add_edge = self.add_edge_or_not()\n",
    "            stop = self.add_node_and_update()\n",
    "\n",
    "        return self.g\n",
    "\n",
    "    def forward(self, actions=None):\n",
    "        # The graph we will work on\n",
    "        self.g = dgl.DGLGraph()\n",
    "\n",
    "        # If there are some features for nodes and edges,\n",
    "        # zero tensors will be set for those of new nodes and edges.\n",
    "        self.g.set_n_initializer(dgl.frame.zero_initializer)\n",
    "        self.g.set_e_initializer(dgl.frame.zero_initializer)\n",
    "\n",
    "        if self.training:\n",
    "            return self.forward_train(actions)\n",
    "        else:\n",
    "            return self.forward_inference()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f15620d6dab3260d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arguments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8679f021b7b97b8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "opts = {\n",
    "    \"node_hidden_size\": 16,\n",
    "    \"num_propagation_rounds\": 1,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"nepochs\": 5,\n",
    "    \"ds_size\": 400,\n",
    "    \"num_generated_samples\": 1000,\n",
    "    \"max_size\" : 300, \n",
    "}\n",
    "\n",
    "model = DGMG(\n",
    "        v_max=opts[\"max_size\"],\n",
    "        node_hidden_size=opts[\"node_hidden_size\"],\n",
    "        num_prop_rounds=opts[\"num_propagation_rounds\"],\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5bb62f529ce28d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(opts[\"nepochs\"]):\n",
    "    t2 = time.time()\n",
    "    batch_count = 0\n",
    "    batch_loss = 0\n",
    "    batch_prob = 0\n",
    "    torch.optimizer.zero_grad()\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "        log_prob = model(actions=data)\n",
    "        prob = log_prob.detach().exp()\n",
    "\n",
    "        loss = -log_prob / opts[\"batch_size\"]\n",
    "        prob_averaged = prob / opts[\"batch_size\"]\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        batch_loss += loss.item()\n",
    "        batch_prob += prob_averaged.item()\n",
    "        batch_count += 1\n",
    "\n",
    "        if batch_count % opts[\"batch_size\"] == 0:\n",
    "            printer.update(\n",
    "                epoch + 1,\n",
    "                {\"averaged_loss\": batch_loss, \"averaged_prob\": batch_prob},\n",
    "            )\n",
    "\n",
    "            if opts[\"clip_grad\"]:\n",
    "                clip_grad_norm_(model.parameters(), opts[\"clip_bound\"])\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss = 0\n",
    "            batch_prob = 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "t3 = time.time()\n",
    "\n",
    "model.eval()\n",
    "evaluator.rollout_and_examine(model, opts[\"num_generated_samples\"])\n",
    "evaluator.write_summary()\n",
    "\n",
    "t4 = time.time()\n",
    "\n",
    "\n",
    "print(\n",
    "    \"It took {} to finish training.\".format(\n",
    "        datetime.timedelta(seconds=t3 - t2)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"It took {} to finish evaluation.\".format(\n",
    "        datetime.timedelta(seconds=t4 - t3)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"--------------------------------------------------------------------------\"\n",
    ")\n",
    "print(\n",
    "    \"On average, an epoch takes {}.\".format(\n",
    "        datetime.timedelta(seconds=(t3 - t2) / opts[\"nepochs\"])\n",
    "    )\n",
    ")\n",
    "\n",
    "del model.g\n",
    "torch.save(model, \"./model.pth\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34e8f71ba2e81a8c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
